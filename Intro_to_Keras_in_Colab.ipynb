{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of C2. Intro to Keras",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliverfoster27/Practical-Machine-Learning/blob/master/Intro_to_Keras_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xhW0sbXbdnC0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q pyyaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0B3_fj18q-Sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "5c8bd967-daae-4b96-dc47-5d29f3681b03"
      },
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!apt install graphviz\n",
        "!pip install pydot pydot-ng\n",
        "!echo \"Double check with Python 3\"\n",
        "!python -c \"import pydot\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pydot-ng in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.3.1)\n",
            "Double check with Python 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7zwaBdZJhdPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5b6255e1-37de-4505-c59d-89cb8de22885"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "print(tf.VERSION)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oPCGxnvKKMgt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Models types\n",
        "### Sequential\n",
        "Simple stack of layers\n",
        "### Functional\n",
        "Multi input, multi output, shared layers, non sequential flows\n",
        "### Model Subclassing\n",
        "Customizable, define foward pass with ```call``` method. Enables [eager execution](https://www.tensorflow.org/guide/eager#build_a_model)"
      ]
    },
    {
      "metadata": {
        "id": "T3gDzVSZM3DX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "451bc35f-d690-4e68-8e12-975ce5a1172d"
      },
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/nicksdemobucket/pima.csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-21 22:42:54--  https://storage.googleapis.com/nicksdemobucket/pima.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23350 (23K) [application/octet-stream]\n",
            "Saving to: ‘pima.csv’\n",
            "\n",
            "\rpima.csv              0%[                    ]       0  --.-KB/s               \rpima.csv            100%[===================>]  22.80K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-21 22:42:54 (80.8 MB/s) - ‘pima.csv’ saved [23350/23350]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J8uNXA2vBtoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d0c09def-f3d4-4670-fc3b-7cae747c0c3d"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('pima.csv')\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BP</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesFunc</th>\n",
              "      <th>Age</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BP  SkinThickness  Insulin   BMI  DiabetesFunc  Age  \\\n",
              "0            6      148  72             35        0  33.6         0.627   50   \n",
              "1            1       85  66             29        0  26.6         0.351   31   \n",
              "2            8      183  64              0        0  23.3         0.672   32   \n",
              "3            1       89  66             23       94  28.1         0.167   21   \n",
              "4            0      137  40             35      168  43.1         2.288   33   \n",
              "\n",
              "   Class  \n",
              "0      1  \n",
              "1      0  \n",
              "2      1  \n",
              "3      0  \n",
              "4      1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "QNYRmwClB5M2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61dbe9b9-760f-4ce9-f5da-8bd0bdc205f2"
      },
      "cell_type": "code",
      "source": [
        "features = df.drop(['Class'], axis=1).values\n",
        "labels = df[['Class']].values\n",
        "print (features.shape, labels.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 8) (768, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W65lRhammQkO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sequential Model"
      ]
    },
    {
      "metadata": {
        "id": "2jJXz3MkhlsB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "9e7526c0-ecd2-441c-f272-310bc70d31c8"
      },
      "cell_type": "code",
      "source": [
        "# maximum simplicity\n",
        "seq_model = Sequential()\n",
        "\n",
        "seq_model.add(Dense(10, activation='relu', input_shape=(8,)))\n",
        "seq_model.add(Dense(10, activation='relu'))\n",
        "seq_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "seq_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "seq_model.fit(features, labels, epochs=10, batch_size=4)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "768/768 [==============================] - 1s 936us/sample - loss: 5.6156 - acc: 0.6510\n",
            "Epoch 2/10\n",
            "768/768 [==============================] - 0s 365us/sample - loss: 5.6084 - acc: 0.6510\n",
            "Epoch 3/10\n",
            "768/768 [==============================] - 0s 394us/sample - loss: 5.6010 - acc: 0.6510\n",
            "Epoch 4/10\n",
            "768/768 [==============================] - 0s 376us/sample - loss: 4.6510 - acc: 0.6484\n",
            "Epoch 5/10\n",
            "768/768 [==============================] - 0s 288us/sample - loss: 0.8711 - acc: 0.6159\n",
            "Epoch 6/10\n",
            "768/768 [==============================] - 0s 293us/sample - loss: 0.6728 - acc: 0.6432\n",
            "Epoch 7/10\n",
            "768/768 [==============================] - 0s 296us/sample - loss: 0.6636 - acc: 0.6393\n",
            "Epoch 8/10\n",
            "768/768 [==============================] - 0s 294us/sample - loss: 0.6430 - acc: 0.6576\n",
            "Epoch 9/10\n",
            "768/768 [==============================] - 0s 292us/sample - loss: 0.6369 - acc: 0.6576\n",
            "Epoch 10/10\n",
            "768/768 [==============================] - 0s 293us/sample - loss: 0.6317 - acc: 0.6693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8deebbca20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "KQhkaZ28mTA9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Functional Model\n",
        "[example](https://cdn-images-1.medium.com/max/2600/1*6hF97Upuqg_LdsqWY6n_wg.png)"
      ]
    },
    {
      "metadata": {
        "id": "VBHDpI2kKY7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "42427c2f-1533-4ffd-8eae-5e6ece4d91ac"
      },
      "cell_type": "code",
      "source": [
        "# more full featured and flexible\n",
        "inputs = keras.Input(shape=(8,))\n",
        "x = Dense(10, activation='relu')(inputs)\n",
        "y = Dense(10, activation='relu')(x)\n",
        "outputs = Dense(1, activation='sigmoid')(y)\n",
        "\n",
        "func_model = keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "func_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "func_model.fit(features, labels, epochs=10, batch_size=4)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "768/768 [==============================] - 0s 491us/sample - loss: 1.6824 - acc: 0.6120\n",
            "Epoch 2/10\n",
            "768/768 [==============================] - 0s 292us/sample - loss: 0.8600 - acc: 0.6667\n",
            "Epoch 3/10\n",
            "768/768 [==============================] - 0s 373us/sample - loss: 0.7215 - acc: 0.6771\n",
            "Epoch 4/10\n",
            "768/768 [==============================] - 0s 323us/sample - loss: 0.6906 - acc: 0.6745\n",
            "Epoch 5/10\n",
            "768/768 [==============================] - 0s 359us/sample - loss: 0.6797 - acc: 0.6810\n",
            "Epoch 6/10\n",
            "768/768 [==============================] - 0s 400us/sample - loss: 0.6615 - acc: 0.6810\n",
            "Epoch 7/10\n",
            "768/768 [==============================] - 0s 315us/sample - loss: 0.6565 - acc: 0.6966\n",
            "Epoch 8/10\n",
            "768/768 [==============================] - 0s 313us/sample - loss: 0.6390 - acc: 0.6940\n",
            "Epoch 9/10\n",
            "768/768 [==============================] - 0s 318us/sample - loss: 0.6304 - acc: 0.6901\n",
            "Epoch 10/10\n",
            "768/768 [==============================] - 0s 323us/sample - loss: 0.6280 - acc: 0.7018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8de95967b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "YRa8kh2-mVGf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Subclassing"
      ]
    },
    {
      "metadata": {
        "id": "PA-jfeUzLdKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "5b5f1558-a0a0-457e-a619-38755622173a"
      },
      "cell_type": "code",
      "source": [
        "# maximally flexible and hackable\n",
        "class ScModel(keras.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(ScModel, self).__init__()\n",
        "    self.dense1 = Dense(10, activation='relu')\n",
        "    self.dense2 = Dense(10, activation='relu')\n",
        "    self.dense3 = Dense(1, activation='sigmoid')\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.dense2(x)\n",
        "    return self.dense3(x)\n",
        "  \n",
        "sc_model = ScModel()\n",
        "\n",
        "sc_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "sc_model.fit(features, labels, epochs=10, batch_size=4)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "768/768 [==============================] - 0s 570us/sample - loss: 1.8323 - acc: 0.5391\n",
            "Epoch 2/10\n",
            "768/768 [==============================] - 0s 373us/sample - loss: 0.9912 - acc: 0.5625\n",
            "Epoch 3/10\n",
            "768/768 [==============================] - 0s 376us/sample - loss: 0.9387 - acc: 0.5495\n",
            "Epoch 4/10\n",
            "768/768 [==============================] - 0s 365us/sample - loss: 0.8827 - acc: 0.5794\n",
            "Epoch 5/10\n",
            "768/768 [==============================] - 0s 368us/sample - loss: 0.8586 - acc: 0.6354\n",
            "Epoch 6/10\n",
            "768/768 [==============================] - 0s 361us/sample - loss: 0.7595 - acc: 0.6341\n",
            "Epoch 7/10\n",
            "768/768 [==============================] - 0s 325us/sample - loss: 0.7032 - acc: 0.6458\n",
            "Epoch 8/10\n",
            "768/768 [==============================] - 0s 296us/sample - loss: 0.6957 - acc: 0.6510\n",
            "Epoch 9/10\n",
            "768/768 [==============================] - 0s 299us/sample - loss: 0.6719 - acc: 0.6602\n",
            "Epoch 10/10\n",
            "768/768 [==============================] - 0s 299us/sample - loss: 0.6870 - acc: 0.6602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8de8f6a2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "j3ItCImGoDSg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize model\n",
        "\n",
        "The summary is useful for simple models, but can be confusing for models that have multiple inputs or outputs.\n",
        "\n",
        "Keras also provides a function to create a plot of the network neural network graph that can make more complex models easier to understand.\n",
        "\n",
        "The plot_model() function in Keras will create a plot of your network. This function takes a few useful arguments:\n",
        "\n",
        "* ```model```: (required) The model that you wish to plot.\n",
        "* ```to_file```: (required) The name of the file to which to save the plot.\n",
        "* ```show_shapes```: (optional, defaults to False) Whether or not to show the output shapes of each layer.\n",
        "* ```show_layer_names```: (optional, defaults to True) Whether or not to show the name for each layer."
      ]
    },
    {
      "metadata": {
        "id": "7KmC42hroBol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "891fe443-fbfa-4679-ccd1-9fdbb0403d3a"
      },
      "cell_type": "code",
      "source": [
        "sc_model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              multiple                  90        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              multiple                  110       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              multiple                  11        \n",
            "=================================================================\n",
            "Total params: 211\n",
            "Trainable params: 211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q7cDLp2yp3kY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[fully connected NN](https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0402.png)"
      ]
    },
    {
      "metadata": {
        "id": "Wrzmlp4npIXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "d6912dff-cd8a-4a21-9e34-ebdb37ad85a7"
      },
      "cell_type": "code",
      "source": [
        "mod = func_model\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    mod, \n",
        "    to_file='{}.png'.format(mod), \n",
        "    show_shapes=True, \n",
        "    show_layer_names=True\n",
        ")\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(retina=True, filename='{}.png'.format(mod))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAGVCAIAAACzSZd7AAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nAADUgNgBAAAVIHYAAEAFiB0AAFDhP7GRmJa28/IvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 180,
              "height": 202
            }
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "90NHWXygtgu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate and predict\n",
        "\n",
        "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy\n",
        "data and a `tf.data.Dataset`.\n",
        "\n",
        "To *evaluate* the inference-mode loss and metrics for the data provided:"
      ]
    },
    {
      "metadata": {
        "id": "fW5GZmB_jI_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e03a02ec-4354-4754-c953-a5e205d97d79"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "some_new_data = np.array([[6., 148.,72.,35.,0.,33.6,0.627, 50.]])\n",
        "some_new_data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "TnbrMxQMjjN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ea32a9d-9c9d-4f43-b034-66107f186af5"
      },
      "cell_type": "code",
      "source": [
        "predicted_labels = sc_model.predict(some_new_data)\n",
        "predicted_labels"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7113905]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "H6tOtNLwjpje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "177b61ff-c663-4cb1-ae74-632f7f99f629"
      },
      "cell_type": "code",
      "source": [
        "sc_model.evaluate(features, labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 0s 107us/sample - loss: 0.6046 - acc: 0.6810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6045760847628117, 0.68098956]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "P3RAov0piqQr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input tf.data datasets\n",
        "\n",
        "Use the Dataset API to scale to large datasets\n",
        "or multi-device training. Pass a `tf.data.Dataset` instance to the `fit`\n",
        "method:\n",
        "\n",
        "Here, the `fit` method uses the `steps_per_epoch` argument—this is the number of\n",
        "training steps the model runs before it moves to the next epoch. Since the\n",
        "`Dataset` yields batches of data, this snippet does not require a `batch_size`."
      ]
    },
    {
      "metadata": {
        "id": "j_f1u0KyL383",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K14bKV7SiXzo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sc_model.fit(dataset, epochs=10, steps_per_epoch=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJSxjNQqk6B8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Custom layers\n",
        "\n",
        "[Arguments](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
        "-\n",
        "[Implementation](https://github.com/keras-team/keras/blob/master/keras/layers/core.py)\n",
        "\n",
        "Create a custom layer by subclassing `tf.keras.layers.Layer` and implementing\n",
        "the following methods:\n",
        "\n",
        "* `build`: Create the weights of the layer. Add weights with the `add_weight`\n",
        "  method.\n",
        "* `call`: Define the forward pass.\n",
        "* `compute_output_shape`: Specify how to compute the output shape of the layer\n",
        "  given the input shape.\n",
        "* Optionally, a layer can be serialized by implementing the `get_config` method\n",
        "  and the `from_config` class method.\n",
        "\n",
        "Here's an example of a custom layer that implements a `matmul` of an input with\n",
        "a kernel matrix:"
      ]
    },
    {
      "metadata": {
        "id": "vd_n_oj8ktYW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layers."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RpoNJ20KihgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyLayer(layers.Layer):\n",
        "\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    self.output_dim = output_dim\n",
        "    super(MyLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
        "    # Create a trainable weight variable for this layer.\n",
        "    self.kernel = self.add_weight(name='kernel',\n",
        "                                  shape=shape,\n",
        "                                  initializer='uniform',\n",
        "                                  trainable=True)\n",
        "    # Make sure to call the `build` method at the end\n",
        "    super(MyLayer, self).build(input_shape)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    shape = tf.TensorShape(input_shape).as_list()\n",
        "    shape[-1] = self.output_dim\n",
        "    return tf.TensorShape(shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super(MyLayer, self).get_config()\n",
        "    base_config['output_dim'] = self.output_dim\n",
        "    return base_config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xemR242ak-yV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(MyLayer(10))\n",
        "model.add(layers.Activation('softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(features, labels, batch_size=4, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IwzvqjrLlJrZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Callbacks\n",
        "\n",
        "A callback is an object passed to a model to customize and extend its behavior\n",
        "during training. You can write your own custom callback, or use the built-in\n",
        "`tf.keras.callbacks` that include:\n",
        "\n",
        "* `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at\n",
        "  regular intervals.\n",
        "* `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning\n",
        "  rate.\n",
        "* `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation\n",
        "  performance has stopped improving.\n",
        "* `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using\n",
        "  [TensorBoard](./summaries_and_tensorboard.md).\n",
        "\n",
        "To use a `tf.keras.callbacks.Callback`, pass it to the model's `fit` method:"
      ]
    },
    {
      "metadata": {
        "id": "SkXcbKEflI7W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "]\n",
        "\n",
        "model.fit(features, labels, batch_size=32, epochs=5, callbacks=callbacks, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "31yq6mUxlZxN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Saving and Restoring\n",
        "### Weights only\n",
        "\n",
        "Save and load the weights of a model using `tf.keras.Model.save_weights`:\n",
        "\n",
        "### Configuration only\n",
        "\n",
        "A model's configuration can be saved—this serializes the model architecture\n",
        "without any weights. A saved configuration can recreate and initialize the same\n",
        "model, even without the code that defined the original model. Keras supports\n",
        "JSON and YAML serialization formats:\n",
        "\n",
        "### Entire model\n",
        "\n",
        "The entire model can be saved to a file that contains the weight values, the\n",
        "model's configuration, and even the optimizer's configuration. This allows you\n",
        "to checkpoint a model and resume training later—from the exact same\n",
        "state—without access to the original code."
      ]
    },
    {
      "metadata": {
        "id": "af1xTnLMlUwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(10, activation='softmax', input_shape=(8,)),\n",
        "  layers.Dense(1, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(features, labels, batch_size=4, epochs=10)\n",
        "\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EcomTxNE5K2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "results = model.predict(some_new_data)\n",
        "results[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GrpOFkPjhXYD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pretrained Models\n",
        "\n",
        "### Use pretrained model\n",
        "### Get embeddings from pretrained models\n",
        "### Finetune pretrained model"
      ]
    },
    {
      "metadata": {
        "id": "FjEmUrRGlE3U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtAYAEHXKBGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aAoBgbX-Hoz0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[pretrained keras models](https://keras.io/applications/)\n",
        "\n",
        "[imagenet classes](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)"
      ]
    },
    {
      "metadata": {
        "id": "LaJ_AvtzjzyX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!wget -O test.png https://www.freepngimg.com/thumb/corn/23-corn-png-image-thumb.png\n",
        "!wget -O test.png https://vignette.wikia.nocookie.net/dino/images/f/f6/JW_triceratops.png/revision/latest?cb=20150407211112"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvGO9WyqjmWG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_path = 'test.png'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "\n",
        "print('Predicted:', decode_predictions(preds, top=10)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QF5Gpp-rTzcx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "31Vs2mDAJAEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1VnAZHlUeDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Other way to do the same thing, just create another model\n",
        "emb_model = Model(inputs=model.inputs, outputs=model.get_layer('avg_pool').output)\n",
        "\n",
        "emb_model.predict(x).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OZmDklyGNuSq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning pre-trained model\n",
        "Provided that our dataset is not drastically different in context to the original dataset, we can use pretrained models like the one above to fine tune to a different task"
      ]
    },
    {
      "metadata": {
        "id": "cI6x46u9NtrV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[print(l) for l in model.layers[-10:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ERzr3uRMQRzb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove the softmax layer\n",
        "model = Model(inputs=model.inputs, outputs=model.get_layer('avg_pool').output)\n",
        "[print(l) for l in model.layers[-10:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qvcxlZokKWMs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Freeze the previous layers\n",
        "for layer in model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# add a couple layers\n",
        "x = Flatten()(model.layers[-1].output)\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(500, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "out = Dense(100, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=model.input, outputs=out)\n",
        "\n",
        "[print(l) for l in model.layers[-10:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pZN-l2IzbhFw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJIqzEuHUol1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCGw3jUNSlFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(lr=0.0001, momentum=0.9), loss='caregorical_crossentropy')\n",
        "model.fit_generator(...,...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IsDT1y9mQ936",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Toy video-QA problem\n",
        "![sequence](https://storage.googleapis.com/nicksdemobucket/Screen%20Shot%202019-02-20%20at%202.17.39%20PM.png)\n",
        "![architecture](https://storage.googleapis.com/nicksdemobucket/Screen%20Shot%202019-02-20%20at%202.17.52%20PM.png)"
      ]
    },
    {
      "metadata": {
        "id": "SNDEpxR8Q-Oq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P9VtSx3-XutP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_voc_size = # Size of vocabulary of possible answers\n",
        "data_generator = # input as question and "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JEzLGoJZXiRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "video = keras.Input(shape=(None, 150, 150, 3), name='video')\n",
        "cnn = InceptionV3(weights='imagenet',\n",
        "include_top=False,\n",
        "pooling='avg')\n",
        "cnn.trainable = False\n",
        "frame_features = layers.TimeDistributed(cnn)(video)\n",
        "video_vector = layers.LSTM(256)(frame_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FmqQ20GVRFaU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question = keras.Input(shape=(None,), dtype='int32', name='question')\n",
        "embedded_words = layers.Embedding(input_voc_size, 256)(question)\n",
        "question_vector = layers.LSTM(128)(embedded_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vw4fNeaWRNDL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = layers.concatenate([video_vector, question_vector])\n",
        "x = layers.Dense(128, activation=tf.nn.relu)(x)\n",
        "predictions = layers.Dense(output_voc_size,\n",
        " activation='softmax',\n",
        " name='predictions')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4pStrrubRRCi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.Model([video, question], predictions)\n",
        "model.compile(optimizer=tf.AdamOptimizer(),loss=keras.losses.categorical_crossentropy)\n",
        "model.fit_generator(data_generator, steps_per_epoch=1000, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dUrsPbBabv1x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Futher Reading\n",
        "* https://github.com/Dataweekends/zero_to_deep_learning_video \n",
        "* https://github.com/keras-team/keras/tree/master/examples \n",
        "* https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras \n",
        "* https://medium.com/tensorflow/tagged/keras\n",
        "* https://github.com/keras-team/keras"
      ]
    }
  ]
}